Using AI in economics research felt like double-sided sword. It enables faster and machine learning but at the same time in a way eliminates one's critical thinking skills.

First Draft Without AI:

The paper touched on lots of things and highlighted a wide range of benefits from using AI in economic research. As you write, you can use it to synthesize text from bullet points and edit paragraphs for improvements in grammar, style, and clarity, ensuring the overall writing maintains a proficient level. I think one thing i noticed that was different than other writings i have read was the rating system the writer proposed. Essentially, there are 3 categories, ○ (empty circle) is experimental capabilities requiring significant oversight; ◐ (half-full) means it is useful but needs careful oversight; then ● (full circle) means it is highly useful and reliable. There are many different LLMs in the market such as Claude, Chatgpt, Deepseek, Grok etc. Most writing and data manipulation tasks rate as highly useful (●), while mathematical derivations remain experimental (○).

Second Draft with Claude AI:

The paper by Anton Korinek touched on numerous topics and highlighted a wide range of benefits from using AI in economic research. As you write, you can use it to synthesize text from bullet points and edit paragraphs for improvements in grammar, style, and clarity, ensuring the overall writing maintains a proficient level. The author specifically notes that LLMs can help with tasks like generating catchy titles, creating tweets to promote papers, and even evaluating text for its stylistic shortcomings.

One thing I noticed that was different than other writings I have read was the practical rating system the writer proposed. Essentially, there are three categories: ○ (empty circle) for experimental capabilities requiring significant oversight; ◐ (half-full) for useful capabilities that need careful oversight; and ● (full circle) for highly useful and reliable features.

There are many different LLMs in the market such as Claude 2 (which notably has a 100,000 token context window for processing entire papers), ChatGPT with GPT-4, and open-source options like Meta's LlaMA 2. The paper provides specific examples using these tools, demonstrating that most writing and data manipulation tasks rate as highly useful (●), while mathematical derivations remain experimental (○). Interestingly, the author found that coding assistance falls somewhere in the middle (◐), citing evidence that GitHub Copilot increased programmer productivity by 56% despite still requiring human oversight.
